{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"betfairlightweight Lightweight, super fast (uses c libraries) pythonic wrapper for Betfair API-NG allowing all betting operations (including market and order streaming) and account operations. Get started... >>> import betfairlightweight >>> trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"app_key\" , certs = \"/certs\" ) >>> trading . login () Request all event types.. >>> event_types = trading . betting . list_event_types () >>> event_types [ < EventTypeResult > , < EventTypeResult > , .. ] Endpoints trading. login trading. login_interactive trading. keep_alive trading. logout trading. betting trading. account trading. navigation trading. scores trading. streaming trading. historical trading.in_play_service trading.race_card Warning in_play_service and race_card are not public endpoints so may break, they are used by the betfair.com website. Dependencies betfairlightweight relies on these libraries: requests - HTTP support Speed install: ciso8601 - C based datetime parsing orjson - Rust based json parsing Installation Install with pip: $ pip install betfairlightweight or to use C/Rust libraries install with $ pip install betfairlightweight [ speed ] betfairlightweight requires Python 3.6+","title":"Introduction"},{"location":"#endpoints","text":"trading. login trading. login_interactive trading. keep_alive trading. logout trading. betting trading. account trading. navigation trading. scores trading. streaming trading. historical trading.in_play_service trading.race_card Warning in_play_service and race_card are not public endpoints so may break, they are used by the betfair.com website.","title":"Endpoints"},{"location":"#dependencies","text":"betfairlightweight relies on these libraries: requests - HTTP support Speed install: ciso8601 - C based datetime parsing orjson - Rust based json parsing","title":"Dependencies"},{"location":"#installation","text":"Install with pip: $ pip install betfairlightweight or to use C/Rust libraries install with $ pip install betfairlightweight [ speed ] betfairlightweight requires Python 3.6+","title":"Installation"},{"location":"advanced/","text":"Advanced Locale Betfair uses slightly different endpoints depending on your country of residence, these can be used by changing the locale on client initialisation: >>> trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"app_key\" , locale = \"italy\" ) spain italy romania sweden australia NEMID Login Danish residents are restricted in how they login due to NemID requirements, this can be handled by replicating the login flow: import re import betfairlightweight trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"app_key\" ) resp = trading . session . post ( url = trading . login_interactive . url , data = { \"username\" : trading . username , \"password\" : trading . password , \"redirectMethod\" : \"POST\" , \"product\" : trading . app_key , \"url\" : \"https://www.betfair.com\" , \"submitForm\" : True , } ) session_token = re . findall ( \"ssoid=(.*?);\" , resp . headers [ \"Set-Cookie\" ] ) trading . set_session_token ( session_token [ 0 ]) print ( trading . betting . list_event_types ()) Session The client assumes requests is used for the http requests but other clients can be used if required, a session object can be passed to the client: >>> session = requests . session () >>> trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"app_key\" , session = session , ) or on a per requests basis: >>> trading . betting . list_event_types ( filter = filters . market_filter ( text_query = 'Horse Racing' ), session = session , ) Response The response object contains the following extra attributes: >>> response = trading . betting . list_event_types ( filter = filters . market_filter ( text_query = 'Horse Racing' ), session = session , ) Raw data / json response: >>> response [ 0 ] . _data { 'eventType' : { 'id' : '7' , 'name' : 'Horse Racing' }, 'marketCount' : 328 } >>> response [ 0 ] . json () { \"eventType\" :{ \"id\" : \"7\" , \"name\" : \"Horse Racing\" }, \"marketCount\" : 328 } Elapsed, created and updated time: >>> response [ 0 ] . elapsed_time 0.14815688133239746 >>> response [ 0 ] . _datetime_created 2020 - 01 - 27 09 : 56 : 32.984387 >>> response [ 0 ] . _datetime_updated 2020 - 01 - 27 09 : 56 : 32.984387 Raw requests response object: >>> response [ 0 ] . _response < Response [ 200 ] > Lightweight In order to return the raw json you can select lightweight on client initialization: >>> trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"app_key\" , certs = \"/certs\" , lightweight = True , ) >>> trading . login () { 'sessionToken' : 'dfgrtegreg===rgrgr' , 'loginStatus' : 'SUCCESS' } or on a per request basis: >>> trading . betting . list_event_types ( filter = filters . market_filter ( text_query = 'Horse Racing' ), lightweight = True , ) [{ 'eventType' : { 'id' : '7' , 'name' : 'Horse Racing' }, 'marketCount' : 328 }] Hint Because lightweight means python doesn't need to create objects it can be considerably faster but harder to work with. Dependencies By default betfairlightweight will install C and Rust based libraries if your os is either linux or darwin (Mac), due to difficulties in installation Windows users can install them separately: $ pip install betfairlightweight [ speed ] Hint If using windows it is likely that visual studio will need to be installed as well. Performance As detailed above using lightweight mode and the [speed] install improves the performance of bflw however it is possible to further improve the speed of backtesting by setting the following on the Listener : listener = betfairlightweight . StreamListener ( max_latency = None , # ignore latency errors output_queue = None , # use generator rather than a queue (faster) lightweight = True , # lightweight mode is faster debug = False , # prevent logging calls on each update (slow) update_clk = False , # do not update clk on updates (not required when backtesting) ) For any further inspiration on speeding up backtesting have a read of the flumine source code, especially patching.py and historicalstream.py","title":"Advanced Usage"},{"location":"advanced/#advanced","text":"","title":"Advanced"},{"location":"advanced/#locale","text":"Betfair uses slightly different endpoints depending on your country of residence, these can be used by changing the locale on client initialisation: >>> trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"app_key\" , locale = \"italy\" ) spain italy romania sweden australia","title":"Locale"},{"location":"advanced/#nemid-login","text":"Danish residents are restricted in how they login due to NemID requirements, this can be handled by replicating the login flow: import re import betfairlightweight trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"app_key\" ) resp = trading . session . post ( url = trading . login_interactive . url , data = { \"username\" : trading . username , \"password\" : trading . password , \"redirectMethod\" : \"POST\" , \"product\" : trading . app_key , \"url\" : \"https://www.betfair.com\" , \"submitForm\" : True , } ) session_token = re . findall ( \"ssoid=(.*?);\" , resp . headers [ \"Set-Cookie\" ] ) trading . set_session_token ( session_token [ 0 ]) print ( trading . betting . list_event_types ())","title":"NEMID Login"},{"location":"advanced/#session","text":"The client assumes requests is used for the http requests but other clients can be used if required, a session object can be passed to the client: >>> session = requests . session () >>> trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"app_key\" , session = session , ) or on a per requests basis: >>> trading . betting . list_event_types ( filter = filters . market_filter ( text_query = 'Horse Racing' ), session = session , )","title":"Session"},{"location":"advanced/#response","text":"The response object contains the following extra attributes: >>> response = trading . betting . list_event_types ( filter = filters . market_filter ( text_query = 'Horse Racing' ), session = session , ) Raw data / json response: >>> response [ 0 ] . _data { 'eventType' : { 'id' : '7' , 'name' : 'Horse Racing' }, 'marketCount' : 328 } >>> response [ 0 ] . json () { \"eventType\" :{ \"id\" : \"7\" , \"name\" : \"Horse Racing\" }, \"marketCount\" : 328 } Elapsed, created and updated time: >>> response [ 0 ] . elapsed_time 0.14815688133239746 >>> response [ 0 ] . _datetime_created 2020 - 01 - 27 09 : 56 : 32.984387 >>> response [ 0 ] . _datetime_updated 2020 - 01 - 27 09 : 56 : 32.984387 Raw requests response object: >>> response [ 0 ] . _response < Response [ 200 ] >","title":"Response"},{"location":"advanced/#lightweight","text":"In order to return the raw json you can select lightweight on client initialization: >>> trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"app_key\" , certs = \"/certs\" , lightweight = True , ) >>> trading . login () { 'sessionToken' : 'dfgrtegreg===rgrgr' , 'loginStatus' : 'SUCCESS' } or on a per request basis: >>> trading . betting . list_event_types ( filter = filters . market_filter ( text_query = 'Horse Racing' ), lightweight = True , ) [{ 'eventType' : { 'id' : '7' , 'name' : 'Horse Racing' }, 'marketCount' : 328 }] Hint Because lightweight means python doesn't need to create objects it can be considerably faster but harder to work with.","title":"Lightweight"},{"location":"advanced/#dependencies","text":"By default betfairlightweight will install C and Rust based libraries if your os is either linux or darwin (Mac), due to difficulties in installation Windows users can install them separately: $ pip install betfairlightweight [ speed ] Hint If using windows it is likely that visual studio will need to be installed as well.","title":"Dependencies"},{"location":"advanced/#performance","text":"As detailed above using lightweight mode and the [speed] install improves the performance of bflw however it is possible to further improve the speed of backtesting by setting the following on the Listener : listener = betfairlightweight . StreamListener ( max_latency = None , # ignore latency errors output_queue = None , # use generator rather than a queue (faster) lightweight = True , # lightweight mode is faster debug = False , # prevent logging calls on each update (slow) update_clk = False , # do not update clk on updates (not required when backtesting) ) For any further inspiration on speeding up backtesting have a read of the flumine source code, especially patching.py and historicalstream.py","title":"Performance"},{"location":"endpoints/","text":"Endpoints Login trading . login () Login Interactive trading . login_interactive () Keep Alive trading . keep_alive () Logout trading . logout () Betting trading . betting . list_event_types () trading . betting . list_competitions () trading . betting . list_time_ranges () trading . betting . list_events () trading . betting . list_market_types () trading . betting . list_countries () trading . betting . list_venues () trading . betting . list_market_catalogue () trading . betting . list_market_book () trading . betting . list_runner_book () trading . betting . list_current_orders () trading . betting . list_cleared_orders () trading . betting . list_market_profit_and_loss () trading . betting . place_orders () trading . betting . cancel_orders () trading . betting . update_orders () trading . betting . replace_orders () Account trading . account . get_account_funds () trading . account . get_account_details () trading . account . get_account_statement () trading . account . list_currency_rates () trading . account . transfer_funds () Navigation trading . navigation . list_navigation () Scores trading . scores . list_race_details () trading . scores . list_available_events () trading . scores . list_scores () trading . scores . list_incidents () Streaming trading . streaming . create_stream () trading . streaming . create_historical_stream () trading . streaming . create_historical_generator_stream () Historical trading . historic . get_my_data () trading . historic . get_collection_options () trading . historic . get_data_size () trading . historic . get_file_list () trading . historic . download_file () In Play Service trading . in_play_service . get_event_timeline () trading . in_play_service . get_event_timelines () trading . in_play_service . get_scores () Race Card trading . race_card . login () trading . race_card . get_race_card () trading . race_card . get_race_result ()","title":"Endpoints"},{"location":"endpoints/#endpoints","text":"","title":"Endpoints"},{"location":"endpoints/#login","text":"trading . login ()","title":"Login"},{"location":"endpoints/#login-interactive","text":"trading . login_interactive ()","title":"Login Interactive"},{"location":"endpoints/#keep-alive","text":"trading . keep_alive ()","title":"Keep Alive"},{"location":"endpoints/#logout","text":"trading . logout ()","title":"Logout"},{"location":"endpoints/#betting","text":"trading . betting . list_event_types () trading . betting . list_competitions () trading . betting . list_time_ranges () trading . betting . list_events () trading . betting . list_market_types () trading . betting . list_countries () trading . betting . list_venues () trading . betting . list_market_catalogue () trading . betting . list_market_book () trading . betting . list_runner_book () trading . betting . list_current_orders () trading . betting . list_cleared_orders () trading . betting . list_market_profit_and_loss () trading . betting . place_orders () trading . betting . cancel_orders () trading . betting . update_orders () trading . betting . replace_orders ()","title":"Betting"},{"location":"endpoints/#account","text":"trading . account . get_account_funds () trading . account . get_account_details () trading . account . get_account_statement () trading . account . list_currency_rates () trading . account . transfer_funds ()","title":"Account"},{"location":"endpoints/#navigation","text":"trading . navigation . list_navigation ()","title":"Navigation"},{"location":"endpoints/#scores","text":"trading . scores . list_race_details () trading . scores . list_available_events () trading . scores . list_scores () trading . scores . list_incidents ()","title":"Scores"},{"location":"endpoints/#streaming","text":"trading . streaming . create_stream () trading . streaming . create_historical_stream () trading . streaming . create_historical_generator_stream ()","title":"Streaming"},{"location":"endpoints/#historical","text":"trading . historic . get_my_data () trading . historic . get_collection_options () trading . historic . get_data_size () trading . historic . get_file_list () trading . historic . download_file ()","title":"Historical"},{"location":"endpoints/#in-play-service","text":"trading . in_play_service . get_event_timeline () trading . in_play_service . get_event_timelines () trading . in_play_service . get_scores ()","title":"In Play Service"},{"location":"endpoints/#race-card","text":"trading . race_card . login () trading . race_card . get_race_card () trading . race_card . get_race_result ()","title":"Race Card"},{"location":"help/","text":"Help Please try the following channels for any support: Betfair Developer Support Slack Group for any help in using the library API Status if things don't seem to be working","title":"Help"},{"location":"help/#help","text":"Please try the following channels for any support: Betfair Developer Support Slack Group for any help in using the library API Status if things don't seem to be working","title":"Help"},{"location":"quickstart/","text":"QuickStart First, start by importing betfairlightweight: >>> import betfairlightweight Now, try logging in: >>> trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"app_key\" , certs = \"/certs\" ) >>> trading . login () < LoginResource > If you do not have certificates setup on your account you can use the interactive login: >>> trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"app_key\" ) >>> trading . login_interactive () < LoginResource > Danger It is strongly recommended to use certificates combined with 2FA when logging in. Once logged in the client stores the login time and session token: >>> trading . session_token 'ergregergreger==regregreg' >>> trading . session_expired False Once logged in you can keep the session alive or logout: >>> trading . keep_alive () < KeepAliveResource > >>> trading . logout () < LogoutResource > Data The client matches the API-NG by splitting the operations per endpoint, therefore in order to list all event types: >>> results = trading . betting . list_event_types () [ < EventTypeResult > , < EventTypeResult > , ... The responses are parsed into python objects allowing easy use: >>> for i in results : print ( i . event_type . id , i . event_type . name , i . market_count ) 1 Soccer 2381 2 Tennis 3402 3 Golf 9 4 Cricket 380 5 Rugby Union 29 ... Or to list events using a market filter: >>> from betfairlightweight import filters >>> racing_filter = filters . market_filter ( text_query = \"Horse Racing\" ) >>> results = trading . betting . list_events ( filter = racing_filter ) [ < EventResult > , < EventResult > , ... >>> for i in results : print ( i . event . id , i . event . name , i . market_count ) 29324768 Aintree 4 th Apr 1 29660708 Arar ( AUS ) 21 st Jan 14 29661349 Aque ( US ) 20 th Jan 9 29636646 Newmarket 3 rd May 1 29660974 Wolv 20 th Jan 32 ... Get static market data using listMarketCatalogue: >>> racing_filter = filters . market_filter ( event_type_ids = [ 7 ], # filter on just horse racing market_countries = [ \"GB\" ], # filter on just GB countries market_type_codes = [ \"WIN\" ], # filter on just WIN market types ) >>> results = trading . betting . list_market_catalogue ( market_projection = [ \"RUNNER_DESCRIPTION\" , \"RUNNER_METADATA\" , \"COMPETITION\" , \"EVENT\" , \"EVENT_TYPE\" , \"MARKET_DESCRIPTION\" , \"MARKET_START_TIME\" , ], filter = racing_filter , max_results = 100 , ) [ < MarketCatalogue > , < MarketCatalogue > , ... >>> for i in results : print ( \" {0} {1:d} : {2:02d} {3} ( {4} )\" . format ( i . market_id , i . market_start_time . hour , i . market_start_time . minute , i . event . venue , i . description . market_type , ) ) 1.167697086 18 : 00 Kempton ( PLACE ) 1.167697085 18 : 00 Kempton ( WIN ) 1.167697089 18 : 00 Kempton ( OTHER_PLACE ) 1.167724518 18 : 20 Sam Houston Race Park ( WIN ) 1.167724731 18 : 29 Tampa Bay Downs ( OTHER_PLACE ) 1.167724730 18 : 29 Tampa Bay Downs ( WIN ) 1.167758596 18 : 30 Kempton ( REV_FORECAST ) 1.167756729 18 : 30 Kempton ( MATCH_BET ) ... Dynamic market price request using listMarketBook >>> market_books = trading . betting . list_market_book ( market_ids = [ \"1.167697085\" ], price_projection = filters . price_projection ( price_data = filters . price_data ( ex_all_offers = True ) ), ) Loop response and print marketBook data: >>> for market_book in market_books : print ( # prints market id, inplay?, status and total matched market_book . market_id , market_book . inplay , market_book . status , market_book . total_matched , ) for runner in market_book . runners : print ( # prints selection id, status, LPT and total matched runner . selection_id , runner . status , runner . last_price_traded , runner . total_matched , ) 1.167697085 False OPEN 230638.0 27024606 ACTIVE 2.38 147131.93 27596981 ACTIVE 3.25 52257.48 26105369 ACTIVE 9.4 15378.91 27596982 ACTIVE 21.0 8247.93 27596980 ACTIVE 24.0 2763.9 27596984 ACTIVE 40.0 1175.25 27596985 ACTIVE 38.0 1260.61 27596983 ACTIVE 70.0 1074.73 27062522 ACTIVE 85.0 1096.03 27596986 ACTIVE 320.0 251.17 Place Order Hint Order requests have limits, please review Betfair documentation for more information. >>> market_id = \"1.131347484\" >>> selection_id = 12029579 >>> limit_order = filters . limit_order ( size = 2.00 , price = 1.01 , persistence_type = \"LAPSE\" ) >>> instruction = filters . place_instruction ( order_type = \"LIMIT\" , selection_id = selection_id , side = \"LAY\" , limit_order = limit_order , ) >>> place_orders = trading . betting . place_orders ( market_id = market_id , instructions = [ instruction ] # list ) >>> print ( place_orders . status ) >>> for order in place_orders . place_instruction_reports : print ( \"Status: {0} , BetId: {1} , Average Price Matched: {2} \" . format ( order . status , order . bet_id , order . average_price_matched ) ) SUCCESS Status : SUCCESS , BetId : 192329047378 , Average Price Matched : 0.0 Update Order >>> bet_id = 192329047378 >>> instruction = filters . update_instruction ( bet_id = bet_id , new_persistence_type = \"PERSIST\" ) >>> update_order = trading . betting . update_orders ( market_id = market_id , instructions = [ instruction ] ) >>> print ( update_order . status ) >>> for order in update_order . update_instruction_reports : print ( \"Status: {0} \" . format ( order . status )) SUCCESS Status : SUCCESS Replace Order >>> instruction = filters . replace_instruction ( bet_id = bet_id , new_price = 1.10 ) >>> replace_order = trading . betting . replace_orders ( market_id = market_id , instructions = [ instruction ] ) >>> print ( replace_order . status ) >>> for order in replace_order . replace_instruction_reports : place_report = order . place_instruction_reports cancel_report = order . cancel_instruction_reports print ( \"Status: {0} , New BetId: {1} , Average Price Matched: {2} \" . format ( order . status , place_report . bet_id , place_report . average_price_matched , ) ) SUCCESS Status : SUCCESS , New BetId : 192329894811 , Average Price Matched : 0.0 Cancel Order Hint Placing a cancel request with no betId will result in all orders for that market being cancelled and placing a cancel request without a marketId will result in all open orders across all markets being cancelled. >>> instruction = filters . cancel_instruction ( bet_id = bet_id , size_reduction = 2.00 ) >>> cancel_order = trading . betting . cancel_orders ( market_id = market_id , instructions = [ instruction ] ) >>> print ( cancel_order . status ) >>> for cancel in cancel_order . cancel_instruction_reports : print ( \"Status: {0} , Size Cancelled: {1} , Cancelled Date: {2} \" . format ( cancel . status , cancel . size_cancelled , cancel . cancelled_date , ) ) SUCCESS Status : SUCCESS , Size Cancelled : 2.0 , Cancelled Date : 2020 - 01 - 22 18 : 08 : 57","title":"QuickStart"},{"location":"quickstart/#quickstart","text":"First, start by importing betfairlightweight: >>> import betfairlightweight Now, try logging in: >>> trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"app_key\" , certs = \"/certs\" ) >>> trading . login () < LoginResource > If you do not have certificates setup on your account you can use the interactive login: >>> trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"app_key\" ) >>> trading . login_interactive () < LoginResource > Danger It is strongly recommended to use certificates combined with 2FA when logging in. Once logged in the client stores the login time and session token: >>> trading . session_token 'ergregergreger==regregreg' >>> trading . session_expired False Once logged in you can keep the session alive or logout: >>> trading . keep_alive () < KeepAliveResource > >>> trading . logout () < LogoutResource >","title":"QuickStart"},{"location":"quickstart/#data","text":"The client matches the API-NG by splitting the operations per endpoint, therefore in order to list all event types: >>> results = trading . betting . list_event_types () [ < EventTypeResult > , < EventTypeResult > , ... The responses are parsed into python objects allowing easy use: >>> for i in results : print ( i . event_type . id , i . event_type . name , i . market_count ) 1 Soccer 2381 2 Tennis 3402 3 Golf 9 4 Cricket 380 5 Rugby Union 29 ... Or to list events using a market filter: >>> from betfairlightweight import filters >>> racing_filter = filters . market_filter ( text_query = \"Horse Racing\" ) >>> results = trading . betting . list_events ( filter = racing_filter ) [ < EventResult > , < EventResult > , ... >>> for i in results : print ( i . event . id , i . event . name , i . market_count ) 29324768 Aintree 4 th Apr 1 29660708 Arar ( AUS ) 21 st Jan 14 29661349 Aque ( US ) 20 th Jan 9 29636646 Newmarket 3 rd May 1 29660974 Wolv 20 th Jan 32 ... Get static market data using listMarketCatalogue: >>> racing_filter = filters . market_filter ( event_type_ids = [ 7 ], # filter on just horse racing market_countries = [ \"GB\" ], # filter on just GB countries market_type_codes = [ \"WIN\" ], # filter on just WIN market types ) >>> results = trading . betting . list_market_catalogue ( market_projection = [ \"RUNNER_DESCRIPTION\" , \"RUNNER_METADATA\" , \"COMPETITION\" , \"EVENT\" , \"EVENT_TYPE\" , \"MARKET_DESCRIPTION\" , \"MARKET_START_TIME\" , ], filter = racing_filter , max_results = 100 , ) [ < MarketCatalogue > , < MarketCatalogue > , ... >>> for i in results : print ( \" {0} {1:d} : {2:02d} {3} ( {4} )\" . format ( i . market_id , i . market_start_time . hour , i . market_start_time . minute , i . event . venue , i . description . market_type , ) ) 1.167697086 18 : 00 Kempton ( PLACE ) 1.167697085 18 : 00 Kempton ( WIN ) 1.167697089 18 : 00 Kempton ( OTHER_PLACE ) 1.167724518 18 : 20 Sam Houston Race Park ( WIN ) 1.167724731 18 : 29 Tampa Bay Downs ( OTHER_PLACE ) 1.167724730 18 : 29 Tampa Bay Downs ( WIN ) 1.167758596 18 : 30 Kempton ( REV_FORECAST ) 1.167756729 18 : 30 Kempton ( MATCH_BET ) ... Dynamic market price request using listMarketBook >>> market_books = trading . betting . list_market_book ( market_ids = [ \"1.167697085\" ], price_projection = filters . price_projection ( price_data = filters . price_data ( ex_all_offers = True ) ), ) Loop response and print marketBook data: >>> for market_book in market_books : print ( # prints market id, inplay?, status and total matched market_book . market_id , market_book . inplay , market_book . status , market_book . total_matched , ) for runner in market_book . runners : print ( # prints selection id, status, LPT and total matched runner . selection_id , runner . status , runner . last_price_traded , runner . total_matched , ) 1.167697085 False OPEN 230638.0 27024606 ACTIVE 2.38 147131.93 27596981 ACTIVE 3.25 52257.48 26105369 ACTIVE 9.4 15378.91 27596982 ACTIVE 21.0 8247.93 27596980 ACTIVE 24.0 2763.9 27596984 ACTIVE 40.0 1175.25 27596985 ACTIVE 38.0 1260.61 27596983 ACTIVE 70.0 1074.73 27062522 ACTIVE 85.0 1096.03 27596986 ACTIVE 320.0 251.17","title":"Data"},{"location":"quickstart/#place-order","text":"Hint Order requests have limits, please review Betfair documentation for more information. >>> market_id = \"1.131347484\" >>> selection_id = 12029579 >>> limit_order = filters . limit_order ( size = 2.00 , price = 1.01 , persistence_type = \"LAPSE\" ) >>> instruction = filters . place_instruction ( order_type = \"LIMIT\" , selection_id = selection_id , side = \"LAY\" , limit_order = limit_order , ) >>> place_orders = trading . betting . place_orders ( market_id = market_id , instructions = [ instruction ] # list ) >>> print ( place_orders . status ) >>> for order in place_orders . place_instruction_reports : print ( \"Status: {0} , BetId: {1} , Average Price Matched: {2} \" . format ( order . status , order . bet_id , order . average_price_matched ) ) SUCCESS Status : SUCCESS , BetId : 192329047378 , Average Price Matched : 0.0","title":"Place Order"},{"location":"quickstart/#update-order","text":">>> bet_id = 192329047378 >>> instruction = filters . update_instruction ( bet_id = bet_id , new_persistence_type = \"PERSIST\" ) >>> update_order = trading . betting . update_orders ( market_id = market_id , instructions = [ instruction ] ) >>> print ( update_order . status ) >>> for order in update_order . update_instruction_reports : print ( \"Status: {0} \" . format ( order . status )) SUCCESS Status : SUCCESS","title":"Update Order"},{"location":"quickstart/#replace-order","text":">>> instruction = filters . replace_instruction ( bet_id = bet_id , new_price = 1.10 ) >>> replace_order = trading . betting . replace_orders ( market_id = market_id , instructions = [ instruction ] ) >>> print ( replace_order . status ) >>> for order in replace_order . replace_instruction_reports : place_report = order . place_instruction_reports cancel_report = order . cancel_instruction_reports print ( \"Status: {0} , New BetId: {1} , Average Price Matched: {2} \" . format ( order . status , place_report . bet_id , place_report . average_price_matched , ) ) SUCCESS Status : SUCCESS , New BetId : 192329894811 , Average Price Matched : 0.0","title":"Replace Order"},{"location":"quickstart/#cancel-order","text":"Hint Placing a cancel request with no betId will result in all orders for that market being cancelled and placing a cancel request without a marketId will result in all open orders across all markets being cancelled. >>> instruction = filters . cancel_instruction ( bet_id = bet_id , size_reduction = 2.00 ) >>> cancel_order = trading . betting . cancel_orders ( market_id = market_id , instructions = [ instruction ] ) >>> print ( cancel_order . status ) >>> for cancel in cancel_order . cancel_instruction_reports : print ( \"Status: {0} , Size Cancelled: {1} , Cancelled Date: {2} \" . format ( cancel . status , cancel . size_cancelled , cancel . cancelled_date , ) ) SUCCESS Status : SUCCESS , Size Cancelled : 2.0 , Cancelled Date : 2020 - 01 - 22 18 : 08 : 57","title":"Cancel Order"},{"location":"streaming/","text":"Streaming Why streaming? If your aim is to take a snapshot of horse markets 3 minutes before the off and at post time, polling (listMarketBook) is a good solution. You will only hit the Betfair API endpoint 2 times per market. But if you want to gather, process and react to data more frequently (e.g. in-play horse racing), polling is inefficient and the reason lies in the way HTTP works. Every time you hit a Betfair API endpoint: Your machine establishes a new connection with the Betfair server. It sends an HTTP request and receives and HTTP response. HTTP requests/responses carry headers, so more data is sent/received. Streaming is more efficient because: The connection gets established once. From that moment, data keeps flowing from Betfair to your machine. There are no data overheads as you would have with polling / HTTP. This results in faster data and less CPU from your machine (and Betfair's) The full docs can be found here Market A market stream can be created like so: import queue import threading import betfairlightweight from betfairlightweight.filters import ( streaming_market_filter , streaming_market_data_filter , ) trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"appKey\" ) trading . login () # create queue output_queue = queue . Queue () # create stream listener listener = betfairlightweight . StreamListener ( output_queue = output_queue ) # create stream stream = trading . streaming . create_stream ( listener = listener ) # create filters (GB WIN racing) market_filter = streaming_market_filter ( event_type_ids = [ \"7\" ], country_codes = [ \"GB\" ], market_types = [ \"WIN\" ] ) market_data_filter = streaming_market_data_filter ( fields = [ \"EX_BEST_OFFERS\" , \"EX_MARKET_DEF\" ], ladder_levels = 3 ) # subscribe streaming_unique_id = stream . subscribe_to_markets ( market_filter = market_filter , market_data_filter = market_data_filter , conflate_ms = 1000 , # send update every 1000ms ) # start stream in a new thread (in production would need err handling) t = threading . Thread ( target = stream . start , daemon = True ) t . start () # check for updates in output queue while True : market_books = output_queue . get () print ( market_books ) for market_book in market_books : print ( market_book , market_book . streaming_unique_id , # unique id of stream (returned from subscribe request) market_book . streaming_update , # json update received market_book . market_definition , # streaming definition, similar to catalogue request market_book . publish_time , # betfair publish time of update ) Order Warning The order stream does not include matched positions, these can be found by making a getCurrentOrders request. However 'price point' matched backs and matched lays are stored in the order cache in matched_lays / matched_backs. Order stream is similar to market: import queue import threading import betfairlightweight from betfairlightweight.filters import streaming_order_filter trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"appKey\" ) trading . login () # create queue output_queue = queue . Queue () # create stream listener listener = betfairlightweight . StreamListener ( output_queue = output_queue ) # create stream stream = trading . streaming . create_stream ( listener = listener ) # create filters (GB WIN racing) order_filter = streaming_order_filter () # subscribe streaming_unique_id = stream . subscribe_to_orders ( order_filter = order_filter , conflate_ms = 1000 , # send update every 1000ms ) # start stream in a new thread (in production would need err handling) t = threading . Thread ( target = stream . start , daemon = True ) t . start () # check for updates in output queue while True : current_orders = output_queue . get () print ( current_orders ) Order - Matches In addition to orders and the moreAvailable flag the streaming output has a matches field which contains a list of the selections with matchedBacks and matchedLays . >>> current_orders . matches [ < bettingresources . Match > , < bettingresources . Match > ] Historical Betfairlightweight can also handle historical streaming data that has been purchased from Betfair or collected yourself. >>> trading = betfairlightweight . APIClient ( \"username\" , \"password\" ) # create listener >>> listener = StreamListener ( max_latency = None ) # create historical stream, update file_path to file location >>> stream = trading . streaming . create_historical_stream ( file_path = \"/tmp/BASIC-1.132153978\" , listener = listener , ) # start stream >>> stream . start () Tip The streaming code is highly optimised however to further improve speed the debug and update_clk flag can be set to False on the listener StreamListener(debug=False, update_clk=False) however update_clk is required to be True when live streaming (resubscribe uses it). The historical stream can be used in the same way as the market/order stream allowing backtesting / market processing. It is also possible to return a generator instead which can be easier to use (no threads) and uses less ram: # create historical generator stream, update directory to file location >>> stream = trading . streaming . create_historical_generator_stream ( file_path = \"/tmp/BASIC-1.132153978\" , listener = listener , ) # create genertaor >>> g = stream . get_generator () >>> for market_books in g (): print ( market_books ) [ < MarketBook > ] .. Snap Instead of waiting for an update you can snap the listener to get an up to date version of the data. >>> market_books = listener . snap ( market_ids = [ \"1.12345323\" ] ) Tip The streaming unique id is returned in the marketBook / orderBook which allows multiple streams to be differentiated if multiple streams feed into the same queue. market_book.streaming_unique_id Resubscribe If you have lost connection and need to resubscribe (prevents a full image being sent) you can provide the following: >>> streaming_unique_id = stream . subscribe_to_markets ( market_filter = market_filter , market_data_filter = market_data_filter , conflate_ms = 1000 , # send update every 1000ms initial_clk = listener . initial_clk , clk = listener . clk , ) Error Handling When used in production it is recommended not to start the stream in a new thread and forgot about it, it will break, errors need to be caught. Please see the example examplestreamingerrhandling.py Sometimes betfair will suspend the stream via the use of a status=503 update, more info here , when the stream is receiving this update the listener.status will be updated: >>> listener . status 503 Listener You can create a custom listener by overriding the listener class: import betfairlightweight class MyListener ( betfairlightweight . StreamListener ): def on_data ( self , raw_data : str ) -> Optional [ bool ]: print ( raw_data ) custom_listener = MyListener () Logging In order to debug the stream update the logging level to DEBUG: import logging logging . basicConfig ( level = logging . DEBUG ) Tip By default max_latency is set to 0.5, this means a warning will be logged if the latency between the publishTime and your machines time is greater than this number. Often you will need to check that your clock is up to date, however this can be removed by setting max_latency=None when initializing the listener.","title":"Streaming"},{"location":"streaming/#streaming","text":"","title":"Streaming"},{"location":"streaming/#why-streaming","text":"If your aim is to take a snapshot of horse markets 3 minutes before the off and at post time, polling (listMarketBook) is a good solution. You will only hit the Betfair API endpoint 2 times per market. But if you want to gather, process and react to data more frequently (e.g. in-play horse racing), polling is inefficient and the reason lies in the way HTTP works. Every time you hit a Betfair API endpoint: Your machine establishes a new connection with the Betfair server. It sends an HTTP request and receives and HTTP response. HTTP requests/responses carry headers, so more data is sent/received. Streaming is more efficient because: The connection gets established once. From that moment, data keeps flowing from Betfair to your machine. There are no data overheads as you would have with polling / HTTP. This results in faster data and less CPU from your machine (and Betfair's) The full docs can be found here","title":"Why streaming?"},{"location":"streaming/#market","text":"A market stream can be created like so: import queue import threading import betfairlightweight from betfairlightweight.filters import ( streaming_market_filter , streaming_market_data_filter , ) trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"appKey\" ) trading . login () # create queue output_queue = queue . Queue () # create stream listener listener = betfairlightweight . StreamListener ( output_queue = output_queue ) # create stream stream = trading . streaming . create_stream ( listener = listener ) # create filters (GB WIN racing) market_filter = streaming_market_filter ( event_type_ids = [ \"7\" ], country_codes = [ \"GB\" ], market_types = [ \"WIN\" ] ) market_data_filter = streaming_market_data_filter ( fields = [ \"EX_BEST_OFFERS\" , \"EX_MARKET_DEF\" ], ladder_levels = 3 ) # subscribe streaming_unique_id = stream . subscribe_to_markets ( market_filter = market_filter , market_data_filter = market_data_filter , conflate_ms = 1000 , # send update every 1000ms ) # start stream in a new thread (in production would need err handling) t = threading . Thread ( target = stream . start , daemon = True ) t . start () # check for updates in output queue while True : market_books = output_queue . get () print ( market_books ) for market_book in market_books : print ( market_book , market_book . streaming_unique_id , # unique id of stream (returned from subscribe request) market_book . streaming_update , # json update received market_book . market_definition , # streaming definition, similar to catalogue request market_book . publish_time , # betfair publish time of update )","title":"Market"},{"location":"streaming/#order","text":"Warning The order stream does not include matched positions, these can be found by making a getCurrentOrders request. However 'price point' matched backs and matched lays are stored in the order cache in matched_lays / matched_backs. Order stream is similar to market: import queue import threading import betfairlightweight from betfairlightweight.filters import streaming_order_filter trading = betfairlightweight . APIClient ( \"username\" , \"password\" , app_key = \"appKey\" ) trading . login () # create queue output_queue = queue . Queue () # create stream listener listener = betfairlightweight . StreamListener ( output_queue = output_queue ) # create stream stream = trading . streaming . create_stream ( listener = listener ) # create filters (GB WIN racing) order_filter = streaming_order_filter () # subscribe streaming_unique_id = stream . subscribe_to_orders ( order_filter = order_filter , conflate_ms = 1000 , # send update every 1000ms ) # start stream in a new thread (in production would need err handling) t = threading . Thread ( target = stream . start , daemon = True ) t . start () # check for updates in output queue while True : current_orders = output_queue . get () print ( current_orders )","title":"Order"},{"location":"streaming/#order-matches","text":"In addition to orders and the moreAvailable flag the streaming output has a matches field which contains a list of the selections with matchedBacks and matchedLays . >>> current_orders . matches [ < bettingresources . Match > , < bettingresources . Match > ]","title":"Order - Matches"},{"location":"streaming/#historical","text":"Betfairlightweight can also handle historical streaming data that has been purchased from Betfair or collected yourself. >>> trading = betfairlightweight . APIClient ( \"username\" , \"password\" ) # create listener >>> listener = StreamListener ( max_latency = None ) # create historical stream, update file_path to file location >>> stream = trading . streaming . create_historical_stream ( file_path = \"/tmp/BASIC-1.132153978\" , listener = listener , ) # start stream >>> stream . start () Tip The streaming code is highly optimised however to further improve speed the debug and update_clk flag can be set to False on the listener StreamListener(debug=False, update_clk=False) however update_clk is required to be True when live streaming (resubscribe uses it). The historical stream can be used in the same way as the market/order stream allowing backtesting / market processing. It is also possible to return a generator instead which can be easier to use (no threads) and uses less ram: # create historical generator stream, update directory to file location >>> stream = trading . streaming . create_historical_generator_stream ( file_path = \"/tmp/BASIC-1.132153978\" , listener = listener , ) # create genertaor >>> g = stream . get_generator () >>> for market_books in g (): print ( market_books ) [ < MarketBook > ] ..","title":"Historical"},{"location":"streaming/#snap","text":"Instead of waiting for an update you can snap the listener to get an up to date version of the data. >>> market_books = listener . snap ( market_ids = [ \"1.12345323\" ] ) Tip The streaming unique id is returned in the marketBook / orderBook which allows multiple streams to be differentiated if multiple streams feed into the same queue. market_book.streaming_unique_id","title":"Snap"},{"location":"streaming/#resubscribe","text":"If you have lost connection and need to resubscribe (prevents a full image being sent) you can provide the following: >>> streaming_unique_id = stream . subscribe_to_markets ( market_filter = market_filter , market_data_filter = market_data_filter , conflate_ms = 1000 , # send update every 1000ms initial_clk = listener . initial_clk , clk = listener . clk , )","title":"Resubscribe"},{"location":"streaming/#error-handling","text":"When used in production it is recommended not to start the stream in a new thread and forgot about it, it will break, errors need to be caught. Please see the example examplestreamingerrhandling.py Sometimes betfair will suspend the stream via the use of a status=503 update, more info here , when the stream is receiving this update the listener.status will be updated: >>> listener . status 503","title":"Error Handling"},{"location":"streaming/#listener","text":"You can create a custom listener by overriding the listener class: import betfairlightweight class MyListener ( betfairlightweight . StreamListener ): def on_data ( self , raw_data : str ) -> Optional [ bool ]: print ( raw_data ) custom_listener = MyListener ()","title":"Listener"},{"location":"streaming/#logging","text":"In order to debug the stream update the logging level to DEBUG: import logging logging . basicConfig ( level = logging . DEBUG ) Tip By default max_latency is set to 0.5, this means a warning will be logged if the latency between the publishTime and your machines time is greater than this number. Often you will need to check that your clock is up to date, however this can be removed by setting max_latency=None when initializing the listener.","title":"Logging"}]}